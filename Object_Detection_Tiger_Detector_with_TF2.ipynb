{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection Tiger Detector with TF2",
      "provenance": [],
      "collapsed_sections": [
        "brpJ5fii5aMj",
        "FNyPgbgQ4WI4",
        "tFXjiGuX57R-",
        "U-JvLquVcMp3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akilesh1989/tiger-object-detection/blob/main/Object_Detection_Tiger_Detector_with_TF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN0imdl9fhjb"
      },
      "source": [
        "#Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6t7Vto8fhYJ"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPS9ZipxLk54"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABJ-RPWqLkGG"
      },
      "source": [
        "import os\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUMPr5MsL8xz"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBi33lHXMCAa"
      },
      "source": [
        "my_gdrive_path = \"/gdrive/My Drive\"\n",
        "project_folder = f\"{my_gdrive_path}/Projects\"\n",
        "WORKSPACE_NAME = \"TIGER_DETECTOR_TF2\"\n",
        "DIR_PATH = f\"{project_folder}/{WORKSPACE_NAME}\"\n",
        "MODEL_PATH = f\"{DIR_PATH}/models\"\n",
        "RESEARCH_PATH = f\"{MODEL_PATH}/research\"\n",
        "ANNOTATIONS_DIR = f\"{DIR_PATH}/annotations\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUFyXCJ9Mbdz"
      },
      "source": [
        "# Mount GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uzpfvcrMdjW"
      },
      "source": [
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvIR2wZhKeE3"
      },
      "source": [
        "# Creating a workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSA8Q8aZLceB"
      },
      "source": [
        "if not os.path.exists(DIR_PATH):\n",
        "  os.makedirs(DIR_PATH)\n",
        "\n",
        "os.listdir(project_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DirnTh9B4NEP"
      },
      "source": [
        "# Installing tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmUtfcJdp8Br"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5HQjw8n4bA6"
      },
      "source": [
        "# Cloning Object Detection Models from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PpC_cUHXOZJ"
      },
      "source": [
        "clone_command = \"git clone https://github.com/tensorflow/models.git\"\n",
        "\n",
        "os.chdir(DIR_PATH)\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DiK5vm_4o1b"
      },
      "source": [
        "## Testing a File in Cloned Object Detection File "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnXKbbpYed0D"
      },
      "source": [
        "os.chdir(RESEARCH_PATH)\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRBV4GNcETpP"
      },
      "source": [
        "SLIM_PATH = f\"{RESEARCH_PATH}/slim\"\n",
        "\n",
        "os.environ['PYTHONPATH'] += f':{MODEL_PATH}:{RESEARCH_PATH}:{SLIM_PATH}'\n",
        "%cp object_detection/packages/tf2/setup.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muENVum6E6S0"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa99DebYEZ9n"
      },
      "source": [
        "# !python -m pip install .\n",
        "!pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcaRCiayEcjK"
      },
      "source": [
        "  !python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLTk9xRMKxiO"
      },
      "source": [
        "# Creating the necessary folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iYy923EKwj3"
      },
      "source": [
        "folders_to_create = ['annotations', 'exported-models', 'pre-trained-models', 'models/my_mobilenet']\n",
        "os.chdir(DIR_PATH)\n",
        "for folder in folders_to_create:\n",
        "  if not os.path.exists(folder):\n",
        "    os.makedirs(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_aF4wMWKb3z"
      },
      "source": [
        "# Getting those images in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI_9ceNWVYro"
      },
      "source": [
        "IMAGES_DIR = f\"{DIR_PATH}/images\"\n",
        "if not os.path.exists(IMAGES_DIR):\n",
        "  os.makedirs(IMAGES_DIR)\n",
        "# upload all you images with their annotations here. You don't have to split\n",
        "# them into training and test set. We'll do it in the Colab notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3wSy2KfjEcQ"
      },
      "source": [
        "TRAIN_DIR = f\"{IMAGES_DIR}/train\"\n",
        "TEST_DIR = f\"{IMAGES_DIR}/test\"\n",
        "\n",
        "if not os.path.exists(TRAIN_DIR):\n",
        "  os.makedirs(TRAIN_DIR)\n",
        "\n",
        "if not os.path.exists(TEST_DIR):\n",
        "  os.makedirs(TEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn8CZ7IsqpC3"
      },
      "source": [
        "import shutil\n",
        "# First move all files to the main dir\n",
        "if len(os.listdir(TRAIN_DIR)) > 0:\n",
        "  for file_name in os.listdir(TRAIN_DIR):\n",
        "    if not file_name in os.listdir(IMAGES_DIR):\n",
        "      shutil.move(os.path.join(TRAIN_DIR, file_name), IMAGES_DIR)\n",
        "\n",
        "if len(os.listdir(TEST_DIR)) > 0:\n",
        "  for file_name in os.listdir(TEST_DIR):\n",
        "    if not file_name in os.listdir(IMAGES_DIR):\n",
        "      shutil.move(os.path.join(TEST_DIR, file_name), IMAGES_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgNxLwBAjeFZ"
      },
      "source": [
        "SPLIT_SIZE = 0.9 # percent of train test split\n",
        "\n",
        "# num_train_files = len(os.listdir(IMAGES_DIR)) * SPLIT_SIZE\n",
        "extensions = (\".jpg\", \".png\", \".jpeg\")\n",
        "all_files = [file for file in os.listdir(IMAGES_DIR) if file.endswith(extensions)]\n",
        "\n",
        "# Check if all the file names are unique. This is very crucial so that we don't end\n",
        "# up with duplicates\n",
        "if len(all_files) != len(set(all_files)):\n",
        "  print(\"DUPLICATE FILE NAMES. FIX IT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy6VdOvmrd7i"
      },
      "source": [
        "import random\n",
        "import shutil\n",
        "\n",
        "num_train_files = int(len(all_files) * SPLIT_SIZE)\n",
        "train_list = random.sample(all_files, num_train_files)\n",
        "len(train_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQW-4CjWjBeg"
      },
      "source": [
        "# Create test and train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRn86tzvtMqP"
      },
      "source": [
        "## Move files to train dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqgDEujgk0Cb"
      },
      "source": [
        "for file_name in train_list:\n",
        "  for extension in extensions:\n",
        "    if extension in file_name:\n",
        "      xml_file_name = file_name.replace(extension, '') + '.xml'\n",
        "      if xml_file_name in os.listdir(IMAGES_DIR):\n",
        "        shutil.move(os.path.join(IMAGES_DIR, file_name), TRAIN_DIR)\n",
        "        shutil.move(os.path.join(IMAGES_DIR, xml_file_name), TRAIN_DIR)\n",
        "\n",
        "print(len(os.listdir(TRAIN_DIR)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRkfZrKrtPwd"
      },
      "source": [
        "## Move files to test dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qSP_j5HtI4q"
      },
      "source": [
        "extensions = (\".jpg\", \".png\", \".jpeg\")\n",
        "all_test_files = [file for file in os.listdir(IMAGES_DIR) if os.path.isfile(os.path.join(IMAGES_DIR, file))]\n",
        "\n",
        "for file_name in all_test_files:\n",
        "  shutil.move(os.path.join(IMAGES_DIR, file_name), TEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brpJ5fii5aMj"
      },
      "source": [
        "# Converting XML Files to CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05IA7AVcMl00"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "  # create annotations dir\n",
        "  if not os.path.exists(ANNOTATIONS_DIR):\n",
        "    os.makedirs(ANNOTATIONS_DIR)\n",
        "  \n",
        "  image_path = os.path.join(os.getcwd(), TRAIN_DIR)\n",
        "  xml_df = xml_to_csv(image_path)\n",
        "  xml_df.to_csv(f'{ANNOTATIONS_DIR}/train_labels.csv', index=None)\n",
        "  \n",
        "  image_path = os.path.join(os.getcwd(), TEST_DIR)\n",
        "  xml_df = xml_to_csv(image_path)\n",
        "  xml_df.to_csv(f'{ANNOTATIONS_DIR}/test_labels.csv',index=None)\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNyPgbgQ4WI4"
      },
      "source": [
        "# Creating TF Record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTIjPgvvM3O4"
      },
      "source": [
        "os.chdir(RESEARCH_PATH)\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZYaKwV79OC"
      },
      "source": [
        "!python setup.py build"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnl8eIh930z"
      },
      "source": [
        "os.environ['PYTHONPATH'] += f':{RESEARCH_PATH}/slim'\n",
        "os.environ['PYTHONPATH'] += f':{RESEARCH_PATH}/object_detection/utils/:{RESEARCH_PATH}/object_detection'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW7MN7hV9UtL"
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30JlQWQnArza"
      },
      "source": [
        "train_csv_path = f\"{ANNOTATIONS_DIR}/train_labels.csv\"\n",
        "train_output_path = f\"{ANNOTATIONS_DIR}/train.tfrecord\"\n",
        "train_images_dir = f\"{DIR_PATH}/images/train/\"\n",
        "\n",
        "test_csv_path = f\"{ANNOTATIONS_DIR}/test_labels.csv\"\n",
        "test_output_path = f\"{ANNOTATIONS_DIR}/test.tfrecord\"\n",
        "test_images_dir = f\"{DIR_PATH}/images/test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEeD0eKxLBYB"
      },
      "source": [
        "LABEL = \"Tiger\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2srjfVpIfo_"
      },
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == LABEL:\n",
        "        return 1\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def convert_to_tfrecord(output_path, image_dir, csv_input):\n",
        "    writer = tf.compat.v1.python_io.TFRecordWriter(output_path)\n",
        "    path = os.path.join(image_dir)\n",
        "    examples = pd.read_csv(csv_input)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_YfeOzwEtvf"
      },
      "source": [
        "convert_to_tfrecord(train_output_path, train_images_dir, train_csv_path)\n",
        "convert_to_tfrecord(test_output_path, test_images_dir, test_csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFXjiGuX57R-"
      },
      "source": [
        "# Downloading Pre-trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW1aDQ_hLQ6_"
      },
      "source": [
        "os.chdir(f\"{DIR_PATH}/pre-trained-models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgmQaf-DLZG3"
      },
      "source": [
        "!curl \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\" --output \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ta4BttWLcIk"
      },
      "source": [
        "import tarfile\n",
        "model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "model_file = model_name + '.tar.gz'\n",
        "tar = tarfile.open(model_file)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "os.remove(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tv5Na3eLnhN"
      },
      "source": [
        "os.listdir(DIR_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPg_ujL9M6uC"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_k5PiJwMrxf"
      },
      "source": [
        "os.chdir(DIR_PATH)\n",
        "%ls pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-JvLquVcMp3"
      },
      "source": [
        "# Add labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsnTPKPAcLmk"
      },
      "source": [
        "os.chdir(ANNOTATIONS_DIR)\n",
        "!touch label_map.pbtxt\n",
        "label_string = \"\"\"\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'Tiger'\n",
        "}\n",
        "\"\"\"\n",
        "with open(os.path.join(ANNOTATIONS_DIR, 'label_map.pbtxt'), 'w') as f:\n",
        "  f.writelines(label_string)\n",
        "f.close()\n",
        "\n",
        "!cat label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZpLKkd7HvC"
      },
      "source": [
        "# Modifying the Config File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv0qdF2K2RRU"
      },
      "source": [
        "pipeline_config_path = f\"{DIR_PATH}/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw_gX04B3n5L"
      },
      "source": [
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "def read_config():\n",
        "    pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "    with tf.io.gfile.GFile(pipeline_config_path, \"r\") as f:                                                                                                                                                                                                                     \n",
        "        proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "        text_format.Merge(proto_str, pipeline)\n",
        "    return pipeline\n",
        "\n",
        "def write_config(pipeline):\n",
        "    config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "    with tf.io.gfile.GFile(pipeline_config_path, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "        f.write(config_text)\n",
        "\n",
        "def modify_config(pipeline):\n",
        "    pipeline.model.ssd.num_classes = 1\n",
        "    pipeline.train_config.fine_tune_checkpoint_type = 'detection'\n",
        "    pipeline.train_config.batch_size = 8\n",
        "    pipeline.train_config.fine_tune_checkpoint = \"pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
        "    pipeline.train_config.num_steps = 25000\n",
        "\n",
        "    # pipeline.train_input_reader.label_map_path = f\"{ANNOTATIONS_DIR}/label_map.pbtxt\"\n",
        "    pipeline.train_input_reader.label_map_path = f\"annotations/label_map.pbtxt\"\n",
        "    pipeline.train_input_reader.tf_record_input_reader.input_path[0] = f\"annotations/train.tfrecord\"\n",
        "\n",
        "    pipeline.eval_input_reader[0].label_map_path = f\"annotations/label_map.pbtxt\"\n",
        "    pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = f\"annotations/test.tfrecord\"\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def setup_pipeline():\n",
        "    pipeline = read_config()\n",
        "    pipeline = modify_config(pipeline)\n",
        "    write_config(pipeline)\n",
        "    # print(pipeline)\n",
        "\n",
        "setup_pipeline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1ISdsxvV44t"
      },
      "source": [
        "Modify the file manually by opening the file in the side bar and double clicking on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw14NQonO7PS"
      },
      "source": [
        "# Tensorboard installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFobN0m8012"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir 'models/my_mobilenet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNn9BkBU7zGl"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMtYIsg3Wc8D"
      },
      "source": [
        "os.chdir(DIR_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asd33NqTXWp7"
      },
      "source": [
        "!cp 'models/research/object_detection/model_main_tf2.py' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAODtxU2faA-"
      },
      "source": [
        "!python model_main_tf2.py \\\n",
        "    --model_dir=models/my_mobilenet \\\n",
        "    --pipeline_config_path=pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22sbYMI8asjx"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbsvESQHJQjF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn0o9EeXHHba"
      },
      "source": [
        "os.listdir(\"pre-trained-models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQclOBjLauGg"
      },
      "source": [
        "os.chdir(DIR_PATH)\n",
        "!python model_main_tf2.py --model_dir=exported-models/checkpoint --pipeline_config_path=pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config --checkpoint_dir=models/my_mobilenet/checkpoint # The folder where the model has saved the checkpoints during training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmEqinlh76rC"
      },
      "source": [
        "# Exporting Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO4xnKenbfQK"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "os.chdir(DIR_PATH)\n",
        "output_directory = 'exported-models/'\n",
        "\n",
        "# goes through the model is the training/ dir and gets the last one.\n",
        "# you could choose a specfic one instead of the last\n",
        "lst = os.listdir(\"models/my_mobilenet/\")\n",
        "lst = [l for l in lst if 'ckpt-' in l and '.index' not in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()]\n",
        "last_model_path = os.path.join('models/my_mobilenet', last_model)\n",
        "print(last_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ3FbvlCsj23"
      },
      "source": [
        "os.chdir(DIR_PATH)\n",
        "!python models/research/object_detection/exporter_main_v2.py \\\n",
        "--input_type=image_tensor \\\n",
        "--pipeline_config_path=pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--output_directory=exported-models \\\n",
        "--trained_checkpoint_dir=models/my_mobilenet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZA8XMKc8pCv"
      },
      "source": [
        "# Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOM30VXpIbq4"
      },
      "source": [
        "os.listdir(f\"{DIR_PATH}/images/train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQknj0c3TtJa"
      },
      "source": [
        "os.chdir(RESEARCH_PATH)\n",
        "!cp object_detection/utils/visualization_utils.py .\n",
        "!cp object_detection/utils/label_map_util.py .\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "import label_map_util as label_map_util\n",
        "import visualization_utils as viz_utils\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "SAVED_MODEL_PATH = f\"{DIR_PATH}/exported-models/saved_model/\"\n",
        "detect_fn = tf.saved_model.load(SAVED_MODEL_PATH)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ_3L8afTopx"
      },
      "source": [
        "for image in os.listdir(f\"{DIR_PATH}/test_images\"):\n",
        "  image_path = f\"{DIR_PATH}/test_images/{image}\"\n",
        "  # image_path = /elephant.jpeg\"\n",
        "  print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  detections = detect_fn(input_tensor)\n",
        "  detections['detection_classes']\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "  print(f\"NUMBER OF TIGERS: {num_detections}\")\n",
        "  detections['detection_boxes'].shape\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  print(detections['detection_scores'])\n",
        "  category_index = label_map_util.create_category_index_from_labelmap(f\"{ANNOTATIONS_DIR}/label_map.pbtxt\")\n",
        "  image_np_with_detections = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.99, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  cv2_imshow(image_np_with_detections)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPgxL9RPRo3"
      },
      "source": [
        "# THE END."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I3OItKMByK8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}